{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjT_Wm1yQshI",
        "outputId": "d04d2300-0087-4ca7-99cd-1a29edaf6a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94Wc9hYuj2zo"
      },
      "outputs": [],
      "source": [
        "##This cell calculates most of the color features, including number of hues(hue_counts), average hue(mean_hue), major hue(max_hue), average saturation(mean_sat), hue contrast(hues_dis), hue histogram(hues_his), major hue ratio(max_hue_pix_ratio)\n",
        "##Refer to formula (7)-(10) in my paper or Page 4 in the reference paper\n",
        "import cv2\n",
        "import numpy as np\n",
        "path1=\"\"\n",
        "hmax=0\n",
        "hues=[]\n",
        "hue_counts=[]\n",
        "max_hue=[]\n",
        "hues_list=[]\n",
        "hues_his=[]\n",
        "hues_dis=[]\n",
        "max_hue_pix_ratio=[]\n",
        "mean_hue=[]\n",
        "mean_sat=[]\n",
        "def hue_distance(h1,h2):\n",
        "    return min(abs(h1-h2),abs(180-h1+h2),abs(180-h2+h1))\n",
        "# files=os.listdir(path)\n",
        "lp=list1\n",
        "for i in range(len(lp)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    # im_path=lp[i]\n",
        "    img = cv2.imread(im_path)\n",
        "    while img.shape[0]>500:\n",
        "        img=cv2.pyrDown(img)# downsampling, because the color template fitting is too slow on large image\n",
        "    img_hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
        "#     imgs_hls.append(img_hls)\n",
        "#     if i%30==0:\n",
        "#         print(i)\n",
        "    im=img_hls[:,:,0]\n",
        "    mean_hue.append(np.mean(im))\n",
        "    mean_sat.append(np.mean(img_hls[:,:,2]))\n",
        "    hue_h=np.zeros((60,))\n",
        "    hue_l=[]\n",
        "    ims=np.int32((img_hls[:,:,2]/255.0)>0.001)\n",
        "    iml=np.int32((img_hls[:,:,1]/255.0)>0.001)\n",
        "    h_bins=np.floor(im/3)*3\n",
        "#     hues.append(h_bins)\n",
        "    hue_c=0\n",
        "    max_pix=0\n",
        "    max_id=-1\n",
        "    for j in range(60):\n",
        "        sign=np.multiply(np.int32(h_bins>=j*3), np.int32(h_bins<(j+1)*3))\n",
        "        pixel_counts=np.sum(np.multiply(np.multiply(ims,sign),iml))\n",
        "        if pixel_counts>50:\n",
        "            hue_c=hue_c+1\n",
        "            hue_h[j]=pixel_counts\n",
        "            hue_l.append(3*j)\n",
        "            if pixel_counts>max_pix:\n",
        "                max_pix=pixel_counts\n",
        "                max_id=j\n",
        "    hue_counts.append(hue_c)\n",
        "    max_hue_pix_ratio.append(max_pix/(im.shape[0]*im.shape[1]))\n",
        "    max_hue.append(3*max_id)\n",
        "    hues_his.append(hue_h)\n",
        "    max_huedis=0\n",
        "    for k in range(len(hue_l)):\n",
        "        for l in range(k):\n",
        "            huedis=hue_distance(hue_l[k],hue_l[l])\n",
        "            if huedis>max_huedis:\n",
        "                max_huedis=huedis\n",
        "    hues_dis.append(max_huedis)\n",
        "#     for w in range(im.shape[0]):\n",
        "#         for h in range(im.shape[1]):\n",
        "#             if im[w][h]>hmax:\n",
        "#                 hmax=im[w][h]\n",
        "    if i%30==0:\n",
        "        print(i)\n",
        "        print(max_pix/(im.shape[0]*im.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell calculates the sharpness feature\n",
        "##Refer to formula (12)-(15) in my paper or Page 6 in the reference paper\n",
        "blurriness=[]\n",
        "for i in range(len(list1)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    img = cv2.imread(im_path)\n",
        "    # while img.shape[0]>500:\n",
        "    #     img=cv2.pyrDown(img)\n",
        "    grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    FFT=np.absolute(np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(grayscale))))\n",
        "    FFT1=FFT/np.sqrt(FFT.size)\n",
        "    score_matrix=np.int32(FFT1>5)\n",
        "    blurriness.append(np.sum(score_matrix)/FFT1.size)\n",
        "    if i%30==0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "k7-1vT6_j6Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell defines two helper functions for next cell which calculates the edge features\n",
        "def compute_thres(im):\n",
        "  thres=np.mean(im)\n",
        "  left=0\n",
        "  right=0\n",
        "  thres_r=np.max(im)\n",
        "  thres_l=np.min(im)\n",
        "  total=np.sum(im)\n",
        "  rat=np.sum(np.multiply(np.int32(im>thres),im))/total\n",
        "  pre_loss=1\n",
        "  bar=0.81\n",
        "  loss=np.abs(rat-bar)\n",
        "  sign=np.int32(im>thres)\n",
        "  while np.abs(rat-bar)>0.00001 and np.abs(pre_loss-loss)>0.0000001:\n",
        "    if rat<bar:\n",
        "      thres_r=thres\n",
        "    elif rat>bar:\n",
        "      thres_l=thres\n",
        "    else:\n",
        "      break\n",
        "    thres=thres_l+0.5*(thres_r-thres_l)\n",
        "    # print(thres_r)\n",
        "    # print(thres)\n",
        "    # print(thres_l)\n",
        "    # print(\"\\n\")\n",
        "    pre_loss=loss\n",
        "    rat=np.sum(np.multiply(np.int32(im>thres),im))/total\n",
        "    loss=np.abs(rat-bar)\n",
        "    # print(loss)\n",
        "    sign=np.int32(im>thres)\n",
        "  return np.sum(sign)/(im.shape[0]*im.shape[1]),sign\n",
        "def get_bbx1(L_abs):\n",
        "  startX=0\n",
        "  startY=0\n",
        "  endX=sign.shape[0]-1\n",
        "  endY=sign.shape[1]-1\n",
        "  start_point=0\n",
        "  end_point=0\n",
        "  bar=0.81\n",
        "  total=bar*np.sum(L_abs)\n",
        "  # Y=sign.shape[0]-1\n",
        "  # X=sign.shape[1]-1\n",
        "  step=(int)(min(L_abs.shape[0],L_abs.shape[1])/100.0)+1\n",
        "  while np.sum(L_abs[startX:endX,startY:endY])>bar*total:\n",
        "    current=np.sum(L_abs[startX:endX,startY:endY])\n",
        "    x1=(endY-startY)/(current-np.sum(L_abs[startX+step:endX,startY:endY])+0.001)\n",
        "    x2=(endY-startY)/(current-np.sum(L_abs[startX:endX-step,startY:endY])+0.001)\n",
        "    y1=(endX-startX)/(current-np.sum(L_abs[startX:endX,startY+step:endY])+0.001)\n",
        "    y2=(endX-startX)/(current-np.sum(L_abs[startX:endX,startY:endY-step])+0.001)\n",
        "    Lxy=[x1,x2,y1,y2]\n",
        "    max_id=0\n",
        "    max_v=x1\n",
        "    for k in range(4):\n",
        "      if Lxy[k]>max_v:\n",
        "        max_id=k\n",
        "        max_v=Lxy[k]\n",
        "    if max_id==0:\n",
        "      startX=startX+step\n",
        "    elif max_id==1:\n",
        "      endX=endX-step\n",
        "    elif max_id==2:\n",
        "      startY=startY+step\n",
        "    else:\n",
        "      endY=endY-step\n",
        "\n",
        "  return startX, endX, startY, endY"
      ],
      "metadata": {
        "id": "IElMwN_Kj9IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell calculates the edge features, including bound box area of 81% edge energy(bbx_area), exact area of the region with 81% edge energy(edge_area), the ratio of pixel with above average edge energy(mean_ratios)\n",
        "##Refer to formula (17)-(19) in my paper or Page 6-7 in the reference paper\n",
        "Laps=[]\n",
        "mean_ratios=[]\n",
        "edge_area=[]\n",
        "bbx_area=[]\n",
        "edge_disX=[]\n",
        "edge_disY=[]\n",
        "ddepth = cv2.CV_64F\n",
        "# ddepth = cv2.CV_16S\n",
        "kernel_size = 3\n",
        "for i in range(len(list1)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    img = cv2.imread(im_path)\n",
        "#     while img.shape[0]>500:\n",
        "#         img=cv2.pyrDown(img)# downsampling, because the color template fitting is too slow on large image\n",
        "    # grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # imgs2.append(img)\n",
        "    im_B=img[:,:,0]\n",
        "    im_G=img[:,:,1]\n",
        "    im_R=img[:,:,2]\n",
        "    blur_G = cv2.GaussianBlur(im_G,(5,5),0)\n",
        "    blur_B = cv2.GaussianBlur(im_B,(5,5),0)\n",
        "    blur_R = cv2.GaussianBlur(im_R,(5,5),0)\n",
        "    LG = cv2.Laplacian(blur_G, ddepth, ksize=kernel_size)\n",
        "    LB = cv2.Laplacian(blur_B, ddepth, ksize=kernel_size)\n",
        "    LR = cv2.Laplacian(blur_R, ddepth, ksize=kernel_size)\n",
        "    L=(LG+LB+LR)/3.0\n",
        "    L_abs=cv2.convertScaleAbs(L)\n",
        "    # Laps.append(L_abs)\n",
        "    mean_ratio=np.mean(np.int32(L_abs>np.mean(L_abs)))\n",
        "    mean_ratios.append(mean_ratio)\n",
        "    area,sign=compute_thres(L_abs)\n",
        "    edge_area.append(area)\n",
        "    # startX, endX, startY, endY=get_bbx(sign)\n",
        "    startX, endX, startY, endY=get_bbx1(L_abs)\n",
        "    edge_disX.append((endX-startX)/sign.shape[0])\n",
        "    edge_disY.append((endY-startY)/sign.shape[1])\n",
        "    bbx_area.append((endX-startX)*(endY-startY)/(sign.shape[0]*sign.shape[1]))\n",
        "    # print(i)\n",
        "    if i%30==0:\n",
        "        print(i) "
      ],
      "metadata": {
        "id": "moUdoK6fkBLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell calculates the composition features, including average x positions(Xs), average y positions(Ys), spatial variance(sqs) and skewness(sks) of three largest regions, \n",
        "##Each element in Xs contains three numbers corresponding to three regions\n",
        "##Refer to formula (24)-(27) in my paper or Page 7 in the reference paper\n",
        "Xs=[]\n",
        "Ys=[]\n",
        "X_sqs=[]\n",
        "Y_sqs=[]\n",
        "sqs=[]\n",
        "sks=[]\n",
        "for i in range(len(list1)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    img = cv2.imread(im_path)\n",
        "    while img.shape[0]>256:\n",
        "        img=cv2.pyrDown(img)# downsampling, because the color template fitting is too slow on large image\n",
        "    # imgs1.append(img)\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    twoDimage = img.reshape((-1,3))\n",
        "    twoDimage = np.float32(twoDimage)\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    K = 6\n",
        "    attempts=10\n",
        "    ret,label,center=cv2.kmeans(twoDimage,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
        "    center = np.uint8(center)\n",
        "    res = center[label.flatten()]\n",
        "    result_image = res.reshape((img.shape))\n",
        "    sign=np.int32(label.reshape((img.shape[0],img.shape[1]))==0)\n",
        "    weight=np.sum(sign)\n",
        "    weights=[weight]\n",
        "    w_ids=[0]\n",
        "    signs=[np.int32(label.reshape((img.shape[0],img.shape[1]))==0)]\n",
        "    for k in range(1,center.shape[0]):\n",
        "      sign=np.int32(label.reshape((img.shape[0],img.shape[1]))==k)\n",
        "      weight=np.sum(sign)\n",
        "      insert_id=len(weights)\n",
        "      for u in range(len(weights)):\n",
        "        if weights[len(weights)-u-1]>=weight:\n",
        "          insert_id=len(weights)-u\n",
        "          break\n",
        "        else:\n",
        "          insert_id=len(weights)-u-1\n",
        "      weights.insert(insert_id, weight)\n",
        "      w_ids.insert(insert_id, k)\n",
        "      signs.insert(insert_id, sign)\n",
        "    # WS.append(weights)\n",
        "    meanX=[]\n",
        "    meanY=[]\n",
        "    varX=[]\n",
        "    varY=[]\n",
        "    var=[]\n",
        "    skew=[]\n",
        "    for j in range(3):\n",
        "      wid=w_ids[j]\n",
        "      sign=signs[j]#np.int32(label.reshape((img.shape[0],img.shape[1]))==wid)\n",
        "      x_ids, y_ids=np.nonzero(sign)\n",
        "      x_ids=np.array(x_ids)/(img.shape[0])\n",
        "      y_ids=np.array(y_ids)/(img.shape[1])\n",
        "      x_c=np.sum(x_ids)/(weights[j])\n",
        "      y_c=np.sum(y_ids)/(weights[j])\n",
        "      x_sq=np.sum(np.square(x_ids-x_c))/(weights[j])\n",
        "      y_sq=np.sum(np.square(y_ids-y_c))/(weights[j])\n",
        "      sq=np.sum(np.square(x_ids-x_c)+np.square(y_ids-y_c))/(weights[j])\n",
        "      sk=np.sum(np.power(y_ids-y_c,3)+np.power(x_ids-x_c,3))/(weights[j])\n",
        "      var.append(sq)\n",
        "      skew.append(sk)\n",
        "      meanX.append(x_c)\n",
        "      meanY.append(y_c)\n",
        "      varX.append(x_sq)\n",
        "      varY.append(y_sq)\n",
        "\n",
        "    Xs.append(meanX)\n",
        "    Ys.append(meanY)\n",
        "    X_sqs.append(varX)\n",
        "    Y_sqs.append(varY) \n",
        "    sqs.append(var) \n",
        "    sks.append(skew)    \n",
        "    if i%30==0:\n",
        "      print(i)"
      ],
      "metadata": {
        "id": "JOrunVHWkEPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell calculates the color and brightness features for the focus region\n",
        "##Refer to the last paragraph of color features in my paper or formula (23)-(25) in Page 8 in the reference paper\n",
        "focus_h=[]\n",
        "focus_l=[]\n",
        "focus_s=[]\n",
        "\n",
        "\n",
        "for i in range(len(list1)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    img = cv2.imread(im_path)\n",
        "    while img.shape[0]>500:\n",
        "        img=cv2.pyrDown(img)# downsampling, because the color template fitting is too slow on large image\n",
        "    img_hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
        "    fr_x0=(int)((1/3.0)*img_hls.shape[0]-(1/20.0)*img_hls.shape[0])\n",
        "    fr_x1=(int)((2/3.0)*img_hls.shape[0]+(1/20.0)*img_hls.shape[0])\n",
        "    fr_y0=(int)((1/3.0)*img_hls.shape[1]-(1/20.0)*img_hls.shape[1])\n",
        "    fr_y1=(int)((2/3.0)*img_hls.shape[1]+(1/20.0)*img_hls.shape[1])\n",
        "    fr=img_hls[fr_x0:fr_x1,fr_y0:fr_y1,:]\n",
        "    fr_h=np.mean(fr[:,:,0])\n",
        "    fr_l=np.mean(fr[:,:,1])\n",
        "    fr_s=np.mean(fr[:,:,2])\n",
        "    focus_h.append(fr_h)\n",
        "    focus_l.append(fr_l)\n",
        "    focus_s.append(fr_s)\n",
        "#     imgs_hls1.append(img_hls)\n",
        "    if i%30==0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "j1fREltxkG5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell calculates the entropy features\n",
        "##Refer to formula (16) in my paper\n",
        "import scipy\n",
        "import scipy.special\n",
        "mean_entr=[]\n",
        "\n",
        "for i in range(len(list1)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    im = cv2.imread(im_path)\n",
        "    while im.shape[0]>500:\n",
        "        im=cv2.pyrDown(im)# downsampling, because the color template fitting is too slow on large image\n",
        "    img=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    win_size=10\n",
        "    entrs=[]\n",
        "    for w in range((int)((img.shape[0])/win_size)):\n",
        "        for h in range((int)((img.shape[1])/win_size)):\n",
        "            x0=w*win_size\n",
        "            x1=(w+1)*win_size\n",
        "            y0=h*win_size\n",
        "            y1=(h+1)*win_size\n",
        "            patch=img[x0:x1,y0:y1]\n",
        "            vals=np.unique(patch)\n",
        "            fr=np.zeros((vals.shape[0],))\n",
        "            for j in range(vals.shape[0]):\n",
        "                fr[j]=np.sum(np.int32(patch==vals[j]))/100\n",
        "            entr=scipy.special.entr(fr)\n",
        "            entrs.append(np.sum(entr))\n",
        "    entrs=np.sort(np.array(entrs))\n",
        "    entrs=entrs[(int)(entrs.shape[0]*0.2):(int)(entrs.shape[0]*0.8)]\n",
        "    mean_entr.append(np.mean(entrs))\n",
        "    \n",
        "    if i%30==0:           \n",
        "        print(i)"
      ],
      "metadata": {
        "id": "qlOUbSLUkPfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##This cell calculates the brightness features, including average brightness(aver_brightness) and brightness contrast(bright_contrasts)\n",
        "##Refer to formula (5)-(6) in my paper or Page 6 in the reference paper\n",
        "aver_brightness=[]\n",
        "bright_contrasts=[]\n",
        "for i in range(len(list1)):\n",
        "    # im_path=path+str(i)+\".png\"\n",
        "    im_path=path1+list1[i]\n",
        "    img = cv2.imread(im_path)\n",
        "    while img.shape[0]>500:\n",
        "        img=cv2.pyrDown(img)# downsampling, because the color template fitting is too slow on large image\n",
        "    img_hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
        "    iml=img_hls[:,:,1]\n",
        "    aver_brightness.append(np.mean(iml))\n",
        "    im_his,bin_edges=np.histogram(iml,bins=40,density=False,range=(0,255))\n",
        "    max_bin=0\n",
        "    max_count=0\n",
        "    total_count=np.sum(im_his)\n",
        "    cumulative=0\n",
        "    for j in range(im_his.shape[0]):\n",
        "        if im_his[j]>max_count:\n",
        "            max_count=im_his[j]\n",
        "            max_bin=j\n",
        "    cumulative=max_count\n",
        "    left_end=max_bin\n",
        "    right_end=max_bin\n",
        "    while cumulative<total_count*0.98:\n",
        "        if left_end-1>=0:\n",
        "            left_end=left_end-1\n",
        "            cumulative=cumulative+im_his[left_end]\n",
        "        if right_end+1<im_his.shape[0] and cumulative<total_count*0.98:\n",
        "            right_end=right_end+1\n",
        "            cumulative=cumulative+im_his[right_end]  \n",
        "    contrast=bin_edges[right_end]-bin_edges[left_end]\n",
        "    bright_contrasts.append(contrast)\n",
        "    if i%30==0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "gOVyQEBYkSbv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}